# Decoding GGUF Models

**This : https://github.com/ggerganov/ggml/blob/master/docs/gguf.md**

**Loading the gguf model in tinygrad** 

Set the path and save the gguf file to safetensor

**Change**
f2 = cwd + "/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf" 
params (according to the model)

```bash
python3 loading.py
```
